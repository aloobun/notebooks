{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bradley TErry Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class BTModel(nn.Module):\n",
    "    def __init__(self, N):\n",
    "        super(BTModel, self).__init__()\n",
    "        self.reward = nn.Parameter(torch.ones(N))\n",
    "        \n",
    "    def forward_exp(self, chosen_id, rejected_id):\n",
    "        reward_chosen = torch.exp(self.reward[chosen_id])\n",
    "        reward_rejected = torch.exp(self.reward[rejected_id])\n",
    "        return reward_chosen / (reward_chosen + reward_rejected)\n",
    "\n",
    "    def forward_sigmoid(self, chosen_id, rejected_id):\n",
    "        reward_chosen = self.reward[chosen_id]\n",
    "        reward_rejected = self.reward[rejected_id]\n",
    "        return torch.sigmoid(reward_chosen - reward_rejected)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return -torch.log(pred) if label == 1 else -torch.log(1 - pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5\n",
    "model = BTModel(N)\n",
    "datas = [(0, 1, 1), (2, 3, 1), (1, 3, 1)]\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.079441547393799\n",
      "Epoch 10, Loss: 1.937548816204071\n",
      "Epoch 20, Loss: 1.811079204082489\n",
      "Epoch 30, Loss: 1.6980656385421753\n",
      "Epoch 40, Loss: 1.5967631340026855\n",
      "Epoch 50, Loss: 1.5056480765342712\n",
      "Epoch 60, Loss: 1.4234036803245544\n",
      "Epoch 70, Loss: 1.3488986492156982\n",
      "Epoch 80, Loss: 1.281165212392807\n",
      "Epoch 90, Loss: 1.2193749248981476\n",
      "Parameter containing:\n",
      "tensor([1.4402, 0.9630, 1.3558, 0.2410, 1.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "for i in range(100):\n",
    "    total_loss = 0\n",
    "    for data in datas:\n",
    "        id_i, id_j, label = data\n",
    "        optimizer.zero_grad()\n",
    "        pred = model.forward_sigmoid(id_i, id_j)\n",
    "        loss = model.loss(pred, torch.tensor(label, dtype=torch.float32))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    if i%10==0 : print(f\"Epoch {i}, Loss: {total_loss}\")\n",
    "\n",
    "print(model.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import LlamaConfig, LlamaForCausalLM\n",
    "torch.manual_seed(42)\n",
    "# 加载模型\n",
    "config = LlamaConfig(vocab_size = 32,      \n",
    "                    hidden_size = 256,\n",
    "                    intermediate_size = 512,\n",
    "                    num_hidden_layers = 2,\n",
    "                    num_attention_heads = 4,\n",
    "                    num_key_value_heads = 4,\n",
    "                    )\n",
    "\n",
    "ref_model = LlamaForCausalLM(config)\n",
    "ref_model.eval()\n",
    "model = LlamaForCausalLM(config) \n",
    "#print(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_length = 6\n",
    "answer_length = 4\n",
    "prompt_chosen =   torch.tensor([[5, 8, 9, 10, 5, 3,   16, 29, 18, 17]], dtype=torch.int64)\n",
    "prompt_rejected = torch.tensor([[5, 8, 9, 10, 5, 3,   26, 14, 31, 0]], dtype=torch.int64)\n",
    "attention_mask =  torch.tensor([[1, 1, 1, 1,  1, 1,   1,  1,  1,  1]], dtype=torch.bool)\n",
    "labels =  torch.tensor([[0, 0, 0, 0,  0, 0,   1,  1,  1,  1]], dtype=torch.bool)\n",
    "\n",
    "x_chosen = {'input_ids':prompt_chosen, 'attention_mask':attention_mask}\n",
    "x_rejected = {'input_ids':prompt_rejected, 'attention_mask':attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits :\n",
      " torch.Size([1, 10, 32])\n",
      "chosen:\n",
      " tensor(17)\n",
      "chosen:\n",
      " tensor([ 0.2971,  0.2909,  0.2621,  0.5977, -0.0441, -0.3005,  0.0452,  0.2285,\n",
      "         0.2922,  0.6789, -0.2369, -0.0842, -0.2411, -0.0244, -0.4583, -0.1332,\n",
      "        -0.2056, -0.2223,  0.3888, -0.1832,  0.1843, -0.2905,  0.7456, -0.2058,\n",
      "         0.1334, -0.0196,  0.0427,  0.5138, -0.2301,  0.0559, -0.2310,  0.0939],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "chosen logprob\n",
      " tensor([-3.2715, -3.2777, -3.3066, -2.9709, -3.6127, -3.8691, -3.5234, -3.3401,\n",
      "        -3.2764, -2.8898, -3.8055, -3.6528, -3.8097, -3.5930, -4.0269, -3.7018,\n",
      "        -3.7742, -3.7910, -3.1798, -3.7519, -3.3843, -3.8591, -2.8231, -3.7744,\n",
      "        -3.4352, -3.5882, -3.5259, -3.0548, -3.7988, -3.5127, -3.7996, -3.4747],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test for get logits and logprob\n",
    "output = ref_model(**x_chosen)\n",
    "\n",
    "def get_probs(logits, labels):\n",
    "    per_token_logps = torch.gather(logits.log_softmax(-1), dim=2, \n",
    "                                   index=labels.unsqueeze(2)).squeeze(2)\n",
    "    return per_token_logps\n",
    "\n",
    "probs_chosen = get_probs(output.logits, prompt_chosen)\n",
    "\n",
    "print('logits :\\n', output.logits.shape)\n",
    "print('chosen:\\n', prompt_chosen[0,-1])\n",
    "print('chosen:\\n', output.logits[0,-1,:])\n",
    "print('chosen logprob\\n', output.logits[0,-1,:].log_softmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7197, 0.7307, 0.7604,\n",
      "         0.6830]], grad_fn=<MulBackward0>)\n",
      "tensor([0.2894], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "#ref/model, chosen/rejected,  logtis/prob value\n",
    "logits_chosen_ref = ref_model(**x_chosen).logits\n",
    "logits_rejected_ref = ref_model(**x_rejected).logits\n",
    "logits_chosen = model(**x_chosen).logits\n",
    "logits_rejected = model(**x_rejected).logits\n",
    "\n",
    "probs_chosen_ref = get_probs(logits_chosen_ref, prompt_chosen)\n",
    "probs_chosen = get_probs(logits_chosen, prompt_chosen)\n",
    "probs_rejected_ref = get_probs(logits_rejected_ref, prompt_rejected)\n",
    "probs_rejected = get_probs(logits_rejected, prompt_rejected)\n",
    "\n",
    "beta = 0.1\n",
    "pi_logratios = probs_chosen - probs_rejected\n",
    "ref_logratios = probs_chosen_ref - probs_rejected_ref\n",
    "logits = pi_logratios - ref_logratios\n",
    "losses = -F.logsigmoid(beta * logits ) * labels\n",
    "print(losses)\n",
    "loss = losses.sum(-1)/attention_mask.sum()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss:0.6931301951408386, pi_rej:0.023953042924404144, log_prob:0.5267601013183594\n",
      "step 100, loss:0.4571150243282318, pi_rej:2.137617444164519e-10, log_prob:0.9052523970603943\n",
      "step 200, loss:0.4340072274208069, pi_rej:4.9613572527650723e-14, log_prob:0.9568975567817688\n",
      "step 300, loss:0.4272170662879944, pi_rej:4.42454224503625e-16, log_prob:0.9727272391319275\n",
      "step 400, loss:0.4240449368953705, pi_rej:1.653651504140485e-17, log_prob:0.9802381992340088\n",
      "step 500, loss:0.4222238063812256, pi_rej:1.3275752523108562e-18, log_prob:0.9845870733261108\n",
      "step 600, loss:0.4210476875305176, pi_rej:1.7141926205286937e-19, log_prob:0.9874109625816345\n",
      "step 700, loss:0.4202280640602112, pi_rej:3.060158553549047e-20, log_prob:0.9893866777420044\n",
      "step 800, loss:0.4196254312992096, pi_rej:6.90988959767223e-21, log_prob:0.990843653678894\n",
      "step 900, loss:0.4191643297672272, pi_rej:1.8646589711505915e-21, log_prob:0.9919609427452087\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = LlamaForCausalLM(config)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "epochs = 1000\n",
    "epochs_print = epochs//10\n",
    "\n",
    "neg_poilicy_prob = [] # pi_l\n",
    "logistic_prob = [] # DPO beta( log(pi_w/pi_ref_w)  - log(pi_l/pi_ref_l))\n",
    "loss_record = [] # DPO loss\n",
    "for i in range(epochs):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward get logits\n",
    "    with torch.no_grad():\n",
    "        logits_chosen_ref = ref_model(**x_chosen).logits\n",
    "        logits_rejected_ref = ref_model(**x_rejected).logits\n",
    "    logits_chosen = model(**x_chosen).logits\n",
    "    logits_rejected = model(**x_rejected).logits\n",
    "\n",
    "    # logits to logprob\n",
    "    probs_chosen_ref = get_probs(logits_chosen_ref, prompt_chosen)\n",
    "    probs_chosen = get_probs(logits_chosen, prompt_chosen)\n",
    "    probs_rejected_ref = get_probs(logits_rejected_ref, prompt_rejected)\n",
    "    probs_rejected = get_probs(logits_rejected, prompt_rejected)\n",
    "\n",
    "    # loss\n",
    "    beta = 0.1\n",
    "    pi_logratios = probs_chosen - probs_rejected\n",
    "    ref_logratios = probs_chosen_ref - probs_rejected_ref\n",
    "    logits = pi_logratios - ref_logratios\n",
    "    losses = -F.logsigmoid( beta * logits ) * label\n",
    "    loss = losses.sum(-1)/attention_mask.sum()\n",
    "\n",
    "    # print(loss)\n",
    "    loss_record.append(loss.item())\n",
    "\n",
    "    # loss back\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    neg_poilicy_prob.append(torch.exp(probs_rejected[:,-1]).item())\n",
    "    logistic_prob.append(torch.sigmoid( beta * logits)[:,-1].item())\n",
    "    \n",
    "    if i % epochs_print == 0:\n",
    "        print(f'step {i}, loss:{loss.item()}, pi_rej:{neg_poilicy_prob[-1]}, log_prob:{logistic_prob[-1]}')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smalls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
